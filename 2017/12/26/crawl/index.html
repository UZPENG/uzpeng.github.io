<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/Article.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/Article.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/Article.png">
  <link rel="mask-icon" href="/Article.png" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://uzpeng.github.io').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: true,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":{"gitalk":{"order":-2}},"activeClass":"gitalk"},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="背景最近女朋友需要利用tableau来做数据可视化的作业，要做数据可视化，那首先可定得要有数据。她们打算用八爪鱼等爬虫软件来抓取数据，结果没成功，原因不明。然后跟我吐槽了一下这个事情，刚好我最近也要学爬虫，本着项目驱动学习的理念，就直接选择了这个项目来练手了。 准备工作编程环境： 123456IntelliJ IDEA 2017.1.5Build #IU-171.4694.70, built on">
<meta property="og:type" content="article">
<meta property="og:title" content="爬虫实践--淘数据网站的数据爬取和存储">
<meta property="og:url" content="https://uzpeng.github.io/2017/12/26/crawl/index.html">
<meta property="og:site_name" content="UZPENG">
<meta property="og:description" content="背景最近女朋友需要利用tableau来做数据可视化的作业，要做数据可视化，那首先可定得要有数据。她们打算用八爪鱼等爬虫软件来抓取数据，结果没成功，原因不明。然后跟我吐槽了一下这个事情，刚好我最近也要学爬虫，本着项目驱动学习的理念，就直接选择了这个项目来练手了。 准备工作编程环境： 123456IntelliJ IDEA 2017.1.5Build #IU-171.4694.70, built on">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://uzpeng.github.io/img/spider_1.png">
<meta property="og:image" content="https://uzpeng.github.io/img/spider-2.png">
<meta property="og:image" content="https://uzpeng.github.io/img/spider-3.png">
<meta property="og:image" content="https://uzpeng.github.io/img/spider_4.png">
<meta property="og:image" content="https://uzpeng.github.io/img/spider-5.png">
<meta property="article:published_time" content="2017-12-26T11:36:59.000Z">
<meta property="article:modified_time" content="2019-12-30T08:10:32.172Z">
<meta property="article:author" content="uzpeng">
<meta property="article:tag" content="网络">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://uzpeng.github.io/img/spider_1.png">

<link rel="canonical" href="https://uzpeng.github.io/2017/12/26/crawl/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>爬虫实践--淘数据网站的数据爬取和存储 | UZPENG</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-101074325-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-101074325-1');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">UZPENG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">write and life.</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://uzpeng.github.io/2017/12/26/crawl/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpeg">
      <meta itemprop="name" content="uzpeng">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="UZPENG">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          爬虫实践--淘数据网站的数据爬取和存储
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-12-26 19:36:59" itemprop="dateCreated datePublished" datetime="2017-12-26T19:36:59+08:00">2017-12-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-12-30 16:10:32" itemprop="dateModified" datetime="2019-12-30T16:10:32+08:00">2019-12-30</time>
              </span>

          
            <span id="/2017/12/26/crawl/" class="post-meta-item leancloud_visitors" data-flag-title="爬虫实践--淘数据网站的数据爬取和存储" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最近女朋友需要利用<code>tableau</code>来做数据可视化的作业，要做数据可视化，那首先可定得要有数据。她们打算用八爪鱼等爬虫软件来抓取数据，结果没成功，原因不明。然后跟我吐槽了一下这个事情，刚好我最近也要学爬虫，本着项目驱动学习的理念，就直接选择了这个项目来练手了。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>编程环境：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">IntelliJ IDEA 2017.1.5</span><br><span class="line">Build #IU-171.4694.70, built on July 4, 2017</span><br><span class="line">Licensed to weapon</span><br><span class="line">JRE: 1.8.0_112-release-736-b21 amd64</span><br><span class="line">JVM: OpenJDK 64-Bit Server VM by JetBrains s.r.o</span><br><span class="line">Windows 10 10.0</span><br></pre></td></tr></table></figure>

<p>编程环境如上所示，因为我Java语言比较熟悉，所以编程语言选择了Java。虽然Java做爬虫语法上面比较累赘，但是Python还没学会，就凑合着用Java写了。</p>
<a id="more"></a>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>我认为的爬虫的流程主要有以下几步  </p>
<ol>
<li>确定目标：确定要抓取的网站和需要抓取的内容。</li>
<li>分析数据请求：利用浏览器的控制台分析网站数据请求的方式（同步请求还是异步请求）。</li>
<li>模拟请求：构造请求，获取数据。</li>
<li>分析数据：分析数据，提取有效信息。</li>
<li>存储数据。将数据存储到本地。</li>
</ol>
<h2 id="实践过程"><a href="#实践过程" class="headerlink" title="实践过程"></a>实践过程</h2><h3 id="确定目标"><a href="#确定目标" class="headerlink" title="确定目标"></a>确定目标</h3><p>我要抓取的网站是<a href="http://www.taosj.com/index.html#/shop/detail/?id=59915065" target="_blank" rel="noopener">淘数据</a>的店铺监控下面的鸿星尔克、德芙、Opus三家店铺的数据，具体的数据如下图所示:<br><img src="/img/spider_1.png" alt=""></p>
<p>主要包含店铺的数据明细、滞销宝贝、宝贝的上新跟踪、宝贝的改名记录、钻石展位、聚划算、淘宝客。</p>
<h3 id="分析数据请求"><a href="#分析数据请求" class="headerlink" title="分析数据请求"></a>分析数据请求</h3><p>打开chrome浏览器，F12打开控制台，点击<code>elements</code>审查元素，通过元素审查我们可知我们需要爬取的数据是通过Ajax异步请求的。接着点击<code>network</code>标签查看网络请求，点击<code>XHR</code>子标签查看Ajax请求，分析请求列表，找到我们需要的请求，单击查看请求详情。 </p>
<p><img src="/img/spider-2.png" alt=""></p>
<blockquote>
<p>PS: 浏览器都是通过HTTP协议进行数据交互的，所以要爬虫的话，还是需要对HTTP有一定的了解。可以参考<a href="https://book.douban.com/subject/10746113/" target="_blank" rel="noopener">《HTTP权威指南》</a>、<a href="https://book.douban.com/subject/25863515/" target="_blank" rel="noopener">《图解HTTP》</a>等书籍。</p>
</blockquote>
<p>从图中我们可以很明显地得到包括请求和响应在内的Http的详细信息，包括请求的方法、请求的URL、请求的主机、请求的头部以及响应状态码，响应体的内容。Http的每个头部都有其含义，具体请参阅《HTTP权威指南》。在这里我们只关心和我们本次请求相关的内容，整理如下：</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td>请求方法</td>
<td>GET</td>
</tr>
<tr>
<td>请求URL</td>
<td><a href="http://taosj.com/...../....stat" target="_blank" rel="noopener">http://taosj.com/...../....stat</a></td>
</tr>
<tr>
<td>Cookie</td>
<td>主要关心<code>auth</code>字段</td>
</tr>
</tbody></table>
<p>请求URL还可以进一步分析其参数组成。以图中的URL为例，<code>http://www.taosj.com/</code>协议和主机地址，<code>data/shop/offer/list</code>主机下的目录，<code>api_name=shop_get_offer_list...stat=</code>长长的参数列表。  </p>
<p>因为访问的数据是需要认证的，常见的认证方式有<code>cookie</code>和<code>token</code>（<a href="https://oauth.net/2/" target="_blank" rel="noopener">OAuth2.0</a>）。经分析报头和尝试请求发现，网站是采用cookie认证的，而且主要的认证cookie字段是<code>auth</code>。  </p>
<p>接着分析响应体，响应体是<code>JSON</code>格式的字符串（关于<code>JSON</code>可以关注其<a href="https://www.json.org/json-zh.html" target="_blank" rel="noopener">官网</a>）。</p>
<p><img src="/img/spider-3.png" alt=""></p>
<h3 id="模拟请求、分析数据、存储数据"><a href="#模拟请求、分析数据、存储数据" class="headerlink" title="模拟请求、分析数据、存储数据"></a>模拟请求、分析数据、存储数据</h3><p>经过上面的分析，我们已经知道了网站数据请求的方式、数据认证的方式、还有请求相关的信息。接下来就可以开展编码工作了。</p>
<p>编码的环境前面已经介绍了，接下来介绍一下使用的开源库。</p>
<blockquote>
<ul>
<li><code>okhttp</code>: 负责http网络请求。*   <code>json-java</code>: java端json实现。</li>
<li><code>gson</code>: google官方的json解析库。</li>
<li><code>poi</code>: apache开源的excel操作库。</li>
</ul>
</blockquote>
<p>项目构建工具使用<code>gradle</code>,构建脚本如下，<a href="https://github.com/UZPENG/Crawler-Demo" target="_blank" rel="noopener">源码</a>在最后。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">group &#39;uzpeng&#39;</span><br><span class="line">version &#39;1.0-SNAPSHOT&#39;</span><br><span class="line">apply plugin: &#39;java&#39;</span><br><span class="line">apply plugin: &#39;idea&#39;</span><br><span class="line">sourceCompatibility &#x3D; 1.8</span><br><span class="line">repositories &#123;</span><br><span class="line">    mavenCentral()</span><br><span class="line">&#125;</span><br><span class="line">dependencies &#123;</span><br><span class="line">    testCompile group: &#39;junit&#39;, name: &#39;junit&#39;, version: &#39;4.12&#39;</span><br><span class="line">    compile group: &#39;org.apache.poi&#39;, name: &#39;poi&#39;, version: &#39;3.17&#39;</span><br><span class="line">    compile group: &#39;com.squareup.okhttp3&#39;, name: &#39;okhttp&#39;, version: &#39;3.9.1&#39;</span><br><span class="line">    compile group: &#39;org.json&#39;, name: &#39;json&#39;, version: &#39;20160810&#39;</span><br><span class="line">    compile group: &#39;com.google.code.gson&#39;, name: &#39;gson&#39;, version: &#39;2.8.2&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>首先，根据浏览器控制台的响应信息，使用<code>GsonFormat</code>插件生成实体类的信息。然后，对照网页显示，确认每一个字段的意义。接着，根据前一个步骤获取的Url和参数信息定义好Url和参数。接着，构造http请求，拿到数据。最后，分析数据，写入excel文件。</p>
<p>我们请求的三个店铺都是不需要认证的，如果需要访问其他店铺数据的话，就需要登录。然后照着上面的分析请求的方法，取出cookie的<code>auth</code>字段，最后在构造请求的时候添加cookie头部信息。</p>
<p>接着介绍一下代码实现，其主要包含以下四个模块：主函数、实体类、网络请求、写入文件。</p>
<p><img src="/img/spider_4.png" alt="">  </p>
<p>网络请求的主要函数如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Response <span class="title">request</span><span class="params">(String url)</span></span>&#123;</span><br><span class="line">      Request request =  <span class="keyword">new</span> Request.Builder()</span><br><span class="line">              .url(url)</span><br><span class="line">              .addHeader(<span class="string">"Cookie"</span>,Cookie)</span><br><span class="line">              .get()</span><br><span class="line">              .build();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">return</span> client.newCall(request).execute();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">          e.printStackTrace();</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>请求很简单，传入我们分析得出的Url和cookie信息，构造请求，然后同步执行，返回结果。</p>
<p>项目整体的数据流大致如下：</p>
<p><img src="/img/spider-5.png" alt="">  </p>
<ol>
<li><code>main</code>函数创建<code>RequestModel</code>，调用<code>RequestModel</code>的<code>requestXXX</code>方法。</li>
<li><code>RequestModel</code>调用<code>HttpClient</code>的<code>request</code>方法。</li>
<li>根据返回的数据调用<code>WriteToExcel()</code>方法。</li>
<li><code>writeProxy</code>创建动态代理。</li>
<li>动态代理的方法里面调用<code>writeIntoExcelManger</code>的<code>outputXXX()</code>方法，最后写入excel。</li>
</ol>
<p>代码实现有两点值得提一下：<br>一是利用jdk动态动态代理，实现AOP，将写入excel的具体内容的代码插入创建excel工作簿和写入本地磁盘之间。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">WriteInvocationHandler outputInvocationHandler = <span class="keyword">new</span> WriteInvocationHandler();</span><br><span class="line">outputInvocationHandler.setWriteIntoExcelProxy(<span class="keyword">new</span> WriteIntoExcelManager());</span><br><span class="line">IWriteIntoExcel proxy = (IWriteIntoExcel) Proxy.newProxyInstance(WriteIntoExcelManager.class.getClassLoader(), new Class[]&#123;IWriteIntoExcel.class&#125;, outputInvocationHandler);</span><br><span class="line">proxy.writeIntoExcel(file, titles, entities, flag);</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">    File file = (File) args[<span class="number">0</span>];</span><br><span class="line">    String[] titles = (String[])args[<span class="number">1</span>];</span><br><span class="line">    List&lt;?&gt; list = (List&lt;?&gt;)args[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">int</span> flag = (Integer) args[<span class="number">3</span>];</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        Workbook workbook = <span class="keyword">new</span> HSSFWorkbook();</span><br><span class="line">        Sheet sheet = workbook.createSheet();</span><br><span class="line">        writeIntoExcelProxy.setSheet(sheet);</span><br><span class="line">        Row row = sheet.createRow(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; titles.length; i++) &#123;</span><br><span class="line">            row.createCell(i).setCellValue(titles[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">switch</span> (flag)&#123;</span><br><span class="line">            <span class="keyword">case</span> WriteProxy.FLAG_OFFER_DETAIL:</span><br><span class="line">                writeIntoExcelProxy.offerDetailOutput(list);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> WriteProxy.FLAG_SHOP_DETAIL:</span><br><span class="line">                writeIntoExcelProxy.shopDetailOutput(list);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> WriteProxy.FLAG_RENAME:</span><br><span class="line">                writeIntoExcelProxy.renameOutput(list);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> WriteProxy.FLAG_UNSALE:</span><br><span class="line">                writeIntoExcelProxy.unSaleOutput(list);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> WriteProxy.FLAG_UPDATE:</span><br><span class="line">                writeIntoExcelProxy.itemUpdateOutput(list);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> WriteProxy.FLAG_JUHUASUAN:</span><br><span class="line">                writeIntoExcelProxy.juHuaSuanOutput(list);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> WriteProxy.FLAG_ZUANSHI:</span><br><span class="line">                writeIntoExcelProxy.zuanShiOutput(list);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> WriteProxy.FLAG_TAOBAOKE:</span><br><span class="line">                writeIntoExcelProxy.taobaokeOutput(list);</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"开始写入文件。。。"</span>);</span><br><span class="line">        workbook.write(<span class="keyword">new</span> FileOutputStream(file));</span><br><span class="line">        System.out.println(<span class="string">"写入完成！"</span>);</span><br><span class="line">     &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">        <span class="keyword">return</span> proxy;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>二是利用buidler模式构造Url参数</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ParamBuilder</span></span>&#123;</span><br><span class="line">        String paraStr = <span class="string">""</span>;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> ParamBuilder <span class="title">addParam</span><span class="params">(String key, String value)</span></span>&#123;</span><br><span class="line">            paraStr += <span class="string">"&amp;"</span>+key+<span class="string">"="</span>+value;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> ParamBuilder <span class="title">addId</span><span class="params">()</span></span>&#123;</span><br><span class="line">            addParam(Key.id, Id);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> ParamBuilder <span class="title">addShopId</span><span class="params">()</span></span>&#123;</span><br><span class="line">            addParam(Key.shopId, Id);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> ParamBuilder <span class="title">addDate</span><span class="params">()</span></span>&#123;</span><br><span class="line">            addParam(Key.startDate, startDate);</span><br><span class="line">            addParam(Key.endDate, endDate);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">build</span><span class="params">()</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> paraStr;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>这里我们将分析数据和存储数据合并在了模拟请求里面，这是因为我们要做的这个爬虫比较简单，数据都是JSON的格式返回回的。如果数据格式比较复杂（如嵌在网页里），则需要构造正则表达式或者利用一些工具分析。同时，因为我们爬取的数据量不太而且不需要持久存储，所以我们直接输出在excel里面了。但是，实际应用中（如全站爬虫），爬取的数据量一般很大，而且需要持久存储、去重、更新维护等等。因此，我们一般会使用数据库，这会让存储数据变得复杂一些。</p>
<h2 id="遇到的问题和解决方案"><a href="#遇到的问题和解决方案" class="headerlink" title="遇到的问题和解决方案"></a>遇到的问题和解决方案</h2><p>问题：Gson解析错误，提示类型不匹配<br>原因：这个问题是由于GsonFormat产生的错误，由于price相关字段的数值为浮点型，但是我们取样的json里面的类型是int，所以会导致解析异常。<br>解决方法：只要将price相关的字段都改为double型即可。  </p>
<p>问题：Gson解析错误提示<code>Unterminated object at line x column xxx</code><br>原因：根据堆栈日志可以定位到json发现，json里面存在类似<code>title&amp;quot;:&amp;quot;\\&amp;quot;Nike 耐克官方 NSW \\&amp;quot;\\&amp;quot;LET THERE BE AIR\\&amp;quot;\\&amp;quot; 大童（男孩）T恤 863808\\&amp;quot;</code>这种字符串，这明显是不符合JSON要求的。<br>解决方案：写一个正则表达式，把非法字符串替换成空串即可。<br>PS：吐槽一下，其实这是他们后台的一个bug，他们的页面也无法访问这种类型的数据，会提示错误。。。</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>至此，我们就实现了一个最简单的爬虫了。现在我们能够将一些接口的数据爬取回来并且写入本地excel文件了。在实现的过程中还利用了builder模式和JDK动态代理增加代码可读性和减少重复性代码。但是，爬虫的内容绝对不止这么简单，我们这个这么简单一方面是因为我们进行爬虫的网站没有做防爬虫机制。另外一方面，我们的爬取的数据是异步请求的，所以从获取到解析都是相对容易的。但是大量的网站的数据是同步获取的，数据都是嵌入在html代码里面，这个时候就需要我们分析html代码。<br>常见的防爬虫措施有以下几种：</p>
<ol>
<li>在网站的robot.txt文件里面声明哪些是爬虫可以访问的数据。</li>
<li>同一IP大量请求后，屏蔽该IP一段时间。</li>
<li>对于请求频率过高的请求要求验证码或谷歌人机验证。</li>
</ol>
<p>豆瓣是防爬虫做得比较严格一个鲜明的例子。我曾经试过在正常浏览的情况下，就是因为浏览得快一点，就在短时间内被多次要求输入验证码。  </p>
<p>既然防爬虫有那么多措施，那么爬虫要怎么应对呢？其实也是有解决方案的。对于封IP的行为，采用公开的IP池的方式，每次使用不同的IP即可。对于请求频率过高要求验证的问题，第一，可以控制请求的频率，第二，人工输入验证码。显而易见，由于web是公开的特征，所以爬虫还是很难完全封掉的。因为你无法准确地判断服务器接收到的请求是爬虫发出的还是用户发出的，所以只能封禁一些明显是爬虫访问的请求，但是爬虫也可以不断地改进从而最大程度模拟用户请求的。  </p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>如上所述，这只是一个简单的爬虫例子，但是麻雀虽小，五张俱全，还是能完整体现整个爬虫的流程的。另外，java爬虫确实是有点累赘，而且大量Java Bean的创建也需要花费不少的时间。最近在学习python，学好之后可以使用python的爬虫框架scrapy去爬取一些带有防爬虫的和多重认证的网站，而且还可以把数据存储在数据库里面、做一些去重等等的工作。爬虫是一个很有趣的过程，有很多东西可以研究的。  </p>
<p>本次的爬虫就到这里啦，下次做了更复杂的爬虫可以再来分享一下。</p>
<p>[1] 源代码：<a href="https://github.com/UZPENG/Crawler-Demo" target="_blank" rel="noopener">https://github.com/UZPENG/Crawler-Demo</a></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%BD%91%E7%BB%9C/" rel="tag"># 网络</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2017/03/04/start/" rel="prev" title="我的博客之旅">
      <i class="fa fa-chevron-left"></i> 我的博客之旅
    </a></div>
      <div class="post-nav-item">
    <a href="/2018/03/05/scrapy/" rel="next" title="scrapy+selenium+headless-chrome爬虫总结">
      scrapy+selenium+headless-chrome爬虫总结 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#背景"><span class="nav-number">1.</span> <span class="nav-text">背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#准备工作"><span class="nav-number">2.</span> <span class="nav-text">准备工作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#流程"><span class="nav-number">3.</span> <span class="nav-text">流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实践过程"><span class="nav-number">4.</span> <span class="nav-text">实践过程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#确定目标"><span class="nav-number">4.1.</span> <span class="nav-text">确定目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分析数据请求"><span class="nav-number">4.2.</span> <span class="nav-text">分析数据请求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模拟请求、分析数据、存储数据"><span class="nav-number">4.3.</span> <span class="nav-text">模拟请求、分析数据、存储数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#遇到的问题和解决方案"><span class="nav-number">5.</span> <span class="nav-text">遇到的问题和解决方案</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分析"><span class="nav-number">6.</span> <span class="nav-text">分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#结语"><span class="nav-number">7.</span> <span class="nav-text">结语</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="uzpeng"
      src="/img/avatar.jpeg">
  <p class="site-author-name" itemprop="name">uzpeng</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/uzpeng" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;uzpeng" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">uzpeng</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">31k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">28 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.6.0
  </div>

        






  <script>
  function leancloudSelector(url) {
    url = encodeURI(url);
    return document.getElementById(url).querySelector('.leancloud-visitors-count');
  }
  if (CONFIG.page.isPost) {
    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.getAttribute('id'));
      var title = visitors.getAttribute('data-flag-title');

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .then(response => response.json())
              .then(() => {
                leancloudSelector(url).innerText = counter.time + 1;
              })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              })
          } else {
              leancloudSelector(url).innerText = 'Counter not initialized! More info at console err msg.';
              console.error('ATTENTION! LeanCloud counter has security bug, see how to solve it here: https://github.com/theme-next/hexo-leancloud-counter-security. \n However, you can still use LeanCloud without security, by setting `security` option to `false`.');
            
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  } else {
    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.getAttribute('id'));
      });

      Counter('get', `/classes/Counter?where=${JSON.stringify({ url: { '$in': entries } })}`)
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length === 0) {
            document.querySelectorAll('.leancloud_visitors .leancloud-visitors-count').forEach(element => {
              element.innerText = 0;
            });
            return;
          }
          for (let item of results) {
            let { url, time } = item;
            leancloudSelector(url).innerText = time;
          }
          for (let url of entries) {
            var element = leancloudSelector(url);
            if (element.innerText == '') {
              element.innerText = 0;
            }
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }
  }

  fetch('https://app-router.leancloud.cn/2/route?appId=eKiOBKe8m32Hsqs8eYEza9pL-gzGzoHsz')
    .then(response => response.json())
    .then(({ api_server }) => {
      var Counter = (method, url, data) => {
        return fetch(`https://${api_server}/1.1${url}`, {
          method: method,
          headers: {
            'X-LC-Id': 'eKiOBKe8m32Hsqs8eYEza9pL-gzGzoHsz',
            'X-LC-Key': 'HKrIqHpa0dUh2bohLDs4Y6tw',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    });
  </script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '6c26908f4522ff667bc3',
      clientSecret: 'be7d02dae19215f672495823f8f00e58e4e72c0b',
      repo: 'uzpeng.github.io',
      owner: 'uzpeng',
      admin: ['uzpeng'],
      id: 'df6fd636bf5f95e7d0e5750ed13b59d4',
        language: '',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
